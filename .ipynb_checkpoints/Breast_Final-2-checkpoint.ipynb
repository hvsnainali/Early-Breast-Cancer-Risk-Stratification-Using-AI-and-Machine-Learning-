{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90cc2f93",
   "metadata": {},
   "source": [
    "\n",
    "# Early Breast Cancer Prediction — Final Notebook (Clean & Concise)\n",
    "\n",
    "**Updated:** 2025-08-08 21:05\n",
    "\n",
    "Streamlined, high-level notebook using a 10% dataset sample.  \n",
    "Run on the full dataset later for final results.\n",
    "\n",
    "**Sections**\n",
    "1. Configuration\n",
    "2. Load & Inspect\n",
    "3. Missing Values\n",
    "4. Exploratory Charts\n",
    "5. Train/Test Split\n",
    "6. Preprocessing\n",
    "7. Class Imbalance (SMOTE)\n",
    "8. Baseline Models + Cross‑Validation\n",
    "9. Test‑Set Evaluation\n",
    "10. (Optional) Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1664a4e7",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7464df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_PATH = \"/mnt/data/sample_10percent.csv\"   # change to full dataset later\n",
    "TARGET_COL = \"cancer\"                          # set your label column\n",
    "TEST_SIZE = 0.2\n",
    "CV_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "N_JOBS = -1\n",
    "\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "                             roc_curve, precision_recall_curve, average_precision_score, ConfusionMatrixDisplay)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    XGB_AVAILABLE = True\n",
    "except:\n",
    "    XGB_AVAILABLE = False\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "pd.set_option(\"display.width\", 160)\n",
    "print(\"Configuration ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbadc25",
   "metadata": {},
   "source": [
    "## 2. Load & Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f235c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head(5))\n",
    "display(df.tail(3))\n",
    "\n",
    "_ = df.info()\n",
    "display(pd.DataFrame(df.dtypes, columns=[\"dtype\"]).T)\n",
    "\n",
    "display(df.describe(include='number').T.head(20))\n",
    "display(df.describe(include='object').T.head(20))\n",
    "\n",
    "assert TARGET_COL in df.columns, f\"TARGET_COL '{TARGET_COL}' not found. Please set it in Section 1.\"\n",
    "print(\"Target column:\", TARGET_COL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb3ebbd",
   "metadata": {},
   "source": [
    "## 3. Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6275ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "missing_pct = (missing / len(df) * 100).round(2)\n",
    "missing_tbl = pd.DataFrame({\"missing_count\": missing, \"missing_pct\": missing_pct})\n",
    "display(missing_tbl.head(30))\n",
    "\n",
    "print(\"Total NaNs:\", int(df.isna().sum().sum()))\n",
    "print(\"Any fully empty columns?:\", bool((missing == len(df)).any()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd092d9",
   "metadata": {},
   "source": [
    "## 4. Exploratory Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceab144",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_SHOW = 6\n",
    "CAT_SHOW = 6\n",
    "\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "for col in num_cols[:NUM_SHOW]:\n",
    "    plt.figure()\n",
    "    df[col].hist(bins=40)\n",
    "    plt.title(f\"Distribution: {col}\"); plt.xlabel(col); plt.ylabel(\"count\")\n",
    "    plt.show()\n",
    "\n",
    "for col in cat_cols[:CAT_SHOW]:\n",
    "    plt.figure()\n",
    "    df[col].astype(str).value_counts().head(15).plot(kind='bar')\n",
    "    plt.title(f\"Top categories: {col}\"); plt.xlabel(col); plt.ylabel(\"count\")\n",
    "    plt.xticks(rotation=45, ha='right'); plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "subset = num_cols[:12]\n",
    "if len(subset) >= 2:\n",
    "    corr = df[subset].corr()\n",
    "    plt.figure(figsize=(7,5))\n",
    "    im = plt.imshow(corr, aspect='auto')\n",
    "    plt.colorbar(im)\n",
    "    plt.title(\"Correlation heatmap (subset)\")\n",
    "    plt.xticks(range(len(subset)), subset, rotation=90); plt.yticks(range(len(subset)), subset)\n",
    "    plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5aa1ba",
   "metadata": {},
   "source": [
    "## 5. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2230e076",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ID_COLUMNS = []\n",
    "\n",
    "X = df.drop(columns=[TARGET_COL] + [c for c in ID_COLUMNS if c in df.columns], errors='ignore')\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "print(\"NaNs in X:\", int(X.isna().sum().sum()), \"| NaNs in y:\", int(y.isna().sum()))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "print(\"Train:\", X_train.shape, \"| Test:\", X_test.shape)\n",
    "\n",
    "print(\"Class balance (train) %:\")\n",
    "display((y_train.value_counts(normalize=True)*100).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aa0d9c",
   "metadata": {},
   "source": [
    "## 6. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e8b1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "numeric_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                         (\"scaler\", StandardScaler())])\n",
    "\n",
    "categorical_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                             (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_pipe, num_cols),\n",
    "    (\"cat\", categorical_pipe, cat_cols)\n",
    "])\n",
    "\n",
    "Xt_train = preprocessor.fit_transform(X_train)\n",
    "Xt_test = preprocessor.transform(X_test)\n",
    "print(\"Shapes:\", Xt_train.shape, Xt_test.shape)\n",
    "print(\"NaNs after preprocess (train)?\", np.isnan(Xt_train).any())\n",
    "print(\"NaNs after preprocess (test)?\", np.isnan(Xt_test).any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7c10ab",
   "metadata": {},
   "source": [
    "## 7. Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a74544",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Class distribution before SMOTE (train) %:\")\n",
    "display((y_train.value_counts(normalize=True)*100).round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7eedaa",
   "metadata": {},
   "source": [
    "## 8. Baseline Models + Cross‑Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0371ea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scorer = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"precision\": \"precision\",\n",
    "    \"recall\": \"recall\",\n",
    "    \"f1\": \"f1\",\n",
    "    \"roc_auc\": \"roc_auc\",\n",
    "    \"average_precision\": \"average_precision\"\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "pipe_logreg = ImbPipeline([(\"prep\", preprocessor),\n",
    "                           (\"smote\", SMOTE(random_state=RANDOM_STATE)),\n",
    "                           (\"clf\", LogisticRegression(max_iter=1000, n_jobs=N_JOBS))])\n",
    "\n",
    "pipe_rf = ImbPipeline([(\"prep\", preprocessor),\n",
    "                       (\"smote\", SMOTE(random_state=RANDOM_STATE)),\n",
    "                       (\"clf\", RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE, n_jobs=N_JOBS))])\n",
    "\n",
    "models = {\"LogReg\": pipe_logreg, \"RF\": pipe_rf}\n",
    "\n",
    "if XGB_AVAILABLE:\n",
    "    pipe_xgb = ImbPipeline([(\"prep\", preprocessor),\n",
    "                            (\"smote\", SMOTE(random_state=RANDOM_STATE)),\n",
    "                            (\"clf\", XGBClassifier(\n",
    "                                n_estimators=400, learning_rate=0.05, subsample=0.8, colsample_bytree=0.8,\n",
    "                                max_depth=6, random_state=RANDOM_STATE, n_jobs=N_JOBS, eval_metric=\"logloss\"))])\n",
    "    models[\"XGB\"] = pipe_xgb\n",
    "\n",
    "cv_results = {}\n",
    "for name, pipe in models.items():\n",
    "    scores = cross_validate(pipe, X_train, y_train, cv=cv, scoring=scorer, n_jobs=N_JOBS)\n",
    "    cv_results[name] = {k: float(np.mean(v)) for k, v in scores.items()}\n",
    "    print(name, \"→\", cv_results[name])\n",
    "\n",
    "cv_df = pd.DataFrame(cv_results).T.sort_values(\"test_roc_auc\", ascending=False)\n",
    "display(cv_df)\n",
    "\n",
    "best_name = cv_df.index[0]\n",
    "print(\"Best model by CV ROC‑AUC:\", best_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a85f18c",
   "metadata": {},
   "source": [
    "## 9. Test‑Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed3030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_pipe = models[best_name]\n",
    "best_pipe.fit(X_train, y_train)\n",
    "\n",
    "proba = best_pipe.predict_proba(X_test)[:,1]\n",
    "pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
    "print(\"Precision:\", precision_score(y_test, pred, zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, pred, zero_division=0))\n",
    "print(\"F1:\", f1_score(y_test, pred, zero_division=0))\n",
    "print(\"ROC‑AUC:\", roc_auc_score(y_test, proba))\n",
    "print(\"PR‑AUC:\", average_precision_score(y_test, proba))\n",
    "\n",
    "plt.figure()\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, pred)\n",
    "plt.title(f\"Confusion Matrix — {best_name}\"); plt.show()\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, proba)\n",
    "plt.figure(); plt.plot(fpr, tpr, label=\"ROC\"); plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"ROC — {best_name}\"); plt.legend(); plt.show()\n",
    "\n",
    "prec, rec, _ = precision_recall_curve(y_test, proba)\n",
    "plt.figure(); plt.plot(rec, prec, label=\"PR\")\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(f\"PR — {best_name}\"); plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f8a610",
   "metadata": {},
   "source": [
    "## 10. (Optional) Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a46c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RUN_TUNING = False\n",
    "\n",
    "if RUN_TUNING:\n",
    "    import scipy.stats as st\n",
    "    if best_name == \"RF\":\n",
    "        dist = {\"clf__n_estimators\": st.randint(300, 900),\n",
    "                \"clf__max_depth\": st.randint(3, 20),\n",
    "                \"clf__min_samples_split\": st.randint(2, 20),\n",
    "                \"clf__min_samples_leaf\": st.randint(1, 20),\n",
    "                \"clf__max_features\": [\"sqrt\", \"log2\", None]}\n",
    "    elif best_name == \"LogReg\":\n",
    "        dist = {\"clf__C\": st.loguniform(1e-3, 1e2),\n",
    "                \"clf__solver\": [\"lbfgs\", \"liblinear\"],\n",
    "                \"clf__penalty\": [\"l2\"]}\n",
    "    elif best_name == \"XGB\" and XGB_AVAILABLE:\n",
    "        dist = {\"clf__n_estimators\": st.randint(300, 900),\n",
    "                \"clf__max_depth\": st.randint(3, 12),\n",
    "                \"clf__learning_rate\": st.uniform(0.01, 0.2),\n",
    "                \"clf__subsample\": st.uniform(0.6, 0.4),\n",
    "                \"clf__colsample_bytree\": st.uniform(0.6, 0.4),\n",
    "                \"clf__gamma\": st.uniform(0.0, 5.0),\n",
    "                \"clf__reg_alpha\": st.uniform(0.0, 1.0),\n",
    "                \"clf__reg_lambda\": st.uniform(0.5, 1.5)}\n",
    "    else:\n",
    "        dist = None\n",
    "\n",
    "    if dist:\n",
    "        tuner = RandomizedSearchCV(models[best_name], param_distributions=dist,\n",
    "                                   n_iter=25, scoring=\"roc_auc\", cv=StratifiedKFold(n_splits=CV_FOLDS,\n",
    "                                   shuffle=True, random_state=RANDOM_STATE),\n",
    "                                   random_state=RANDOM_STATE, n_jobs=N_JOBS, verbose=1)\n",
    "        tuner.fit(X_train, y_train)\n",
    "        print(\"Best params:\", tuner.best_params_)\n",
    "        print(\"Best CV ROC‑AUC:\", tuner.best_score_)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
