{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "681c9bac",
   "metadata": {},
   "source": [
    "\n",
    "# Early Breast Cancer Risk Stratification – SHAP Interpretability\n",
    "\n",
    "In this iteration, we assume access to the full **1.5 million**‑record risk factor dataset (the 150 k sample used here represents roughly 10 % of it) and focus on model interpretability using **SHAP** (SHapley Additive exPlanations).  SHAP values provide insight into how each feature contributes to individual predictions, offering transparency crucial for clinical applications.  We build a tree‑based model and compute SHAP values, taking into account that each row summarises many women via the `count` column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f65f9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## 1. Load the data and prepare training/testing sets\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the 10% sample dataset (stand‑in for full dataset)\n",
    "df = pd.read_csv('/home/oai/share/sample_10percent.csv')\n",
    "\n",
    "# Remove rows with unknown target\n",
    "df = df[df['breast_cancer_history'] != 9].copy()\n",
    "\n",
    "# Define categorical and numeric columns\n",
    "categorical_cols = [col for col in df.columns if col not in ['year','count','breast_cancer_history']]\n",
    "numerical_cols = ['year']\n",
    "\n",
    "# Separate target and features\n",
    "y = df['breast_cancer_history']\n",
    "X = df.drop(columns=['breast_cancer_history'])\n",
    "\n",
    "# Capture sample weights\n",
    "weights = X['count'].values\n",
    "\n",
    "# Remove count from features for modelling\n",
    "X = X.drop(columns=['count'])\n",
    "\n",
    "# Build preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('categorical', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('numeric', 'passthrough', numerical_cols)\n",
    "])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(\n",
    "    X, y, weights, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print('Train size:', X_train.shape)\n",
    "print('Test size:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e95b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## 2. Train a tree‑based model for SHAP analysis\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Use a reasonably strong random forest; in practice one would use tuned hyperparameters\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=400, max_depth=20, class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# Fit model using sample weights\n",
    "model.fit(X_train, y_train, classifier__sample_weight=w_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "prob_test = model.predict_proba(X_test)[:,1]\n",
    "pred_test = (prob_test >= 0.5).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, pred_test)\n",
    "f1 = f1_score(y_test, pred_test)\n",
    "roc_auc = roc_auc_score(y_test, prob_test)\n",
    "\n",
    "print('Random Forest performance:')\n",
    "print('  Accuracy:', acc)\n",
    "print('  F1 score:', f1)\n",
    "print('  ROC AUC:', roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69415de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## 3. SHAP analysis for interpretability\n",
    "\n",
    "# SHAP can be computationally intensive.  We'll sample a subset of the training data to compute SHAP values.\n",
    "# We also need to transform the data using the fitted preprocessor and extract the tree model.\n",
    "\n",
    "# Attempt to import shap; install if not already available\n",
    "import importlib\n",
    "try:\n",
    "    import shap\n",
    "except ImportError:\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install shap\n",
    "    import shap\n",
    "\n",
    "# Prepare a background sample (1000 samples) for SHAP explainer\n",
    "sample_indices = np.random.choice(len(X_train), size=min(1000, len(X_train)), replace=False)\n",
    "X_train_sample = X_train.iloc[sample_indices]\n",
    "\n",
    "# Fit the preprocessor on full training data and transform samples\n",
    "X_train_enc = model.named_steps['preprocessor'].fit_transform(X_train)\n",
    "X_test_enc = model.named_steps['preprocessor'].transform(X_test)\n",
    "\n",
    "# Extract the trained RandomForestClassifier\n",
    "rf = model.named_steps['classifier']\n",
    "\n",
    "# Use TreeExplainer for tree-based models\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "\n",
    "# Compute SHAP values for the test set (limit to first 200 samples for speed)\n",
    "sample_for_shap = min(200, X_test_enc.shape[0])\n",
    "shap_values = explainer.shap_values(X_test_enc[:sample_for_shap])\n",
    "\n",
    "# Get feature names from the one‑hot encoder\n",
    "feature_names = list(model.named_steps['preprocessor'].transformers_[0][1].get_feature_names_out(categorical_cols)) + numerical_cols\n",
    "\n",
    "# Create a SHAP summary plot for the positive class (index 1)\n",
    "shap.summary_plot(shap_values[1], X_test_enc[:sample_for_shap], feature_names=feature_names, plot_type='bar', show=False)\n",
    "plt.title('Mean absolute SHAP values – Random Forest')\n",
    "plt.show()\n",
    "\n",
    "# Additionally, display a beeswarm plot to visualise the distribution of SHAP values\n",
    "shap.summary_plot(shap_values[1], X_test_enc[:sample_for_shap], feature_names=feature_names, show=False)\n",
    "plt.title('SHAP summary plot (class = 1) – Random Forest')\n",
    "plt.show()\n",
    "\n",
    "# Explain a single instance (e.g. the first test sample)\n",
    "instance_index = 0\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1][instance_index], features=X_test_enc[instance_index], feature_names=feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877811ec",
   "metadata": {},
   "source": [
    "\n",
    "# ## 4. Discussion: Interpreting SHAP outputs\n",
    "\n",
    "The SHAP bar plot ranks features by their mean absolute contribution to the model’s output across the sampled test instances.  Features with higher mean SHAP values influence predictions more strongly.  For example, age group, BMI group, breast density and family history typically show higher contributions, consistent with our earlier feature‑importance analyses.\n",
    "\n",
    "The beeswarm plot provides a more detailed view: each point represents a SHAP value for a feature in an individual case.  Points are coloured by the original feature value (after encoding), showing how high or low values push the prediction towards or away from the positive class (prior breast cancer).  Clusters of points reveal whether the model’s decisions are consistent across different subgroups.\n",
    "\n",
    "Finally, the force plot explains an individual prediction by showing how each feature contributes to pushing the base value (average prediction) towards the final probability for that instance.  Such local explanations are useful when discussing specific recommendations with clinicians or patients.\n",
    "\n",
    "Remember that SHAP analyses are approximate when working with aggregated data—each row summarises many individuals, so the interpretation reflects the average effect within each group rather than specific individuals.\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
