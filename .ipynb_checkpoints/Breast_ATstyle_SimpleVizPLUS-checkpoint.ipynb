{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eedd8d0",
   "metadata": {},
   "source": [
    "\n",
    "# Early Breast Cancer Prediction — AT‑Style **Simple & Visual PLUS** (Procedural)\n",
    "\n",
    "**Updated:** 2025-08-08 21:37\n",
    "\n",
    "Long, simple, and highly visual. No custom `def` functions, minimal branching.  \n",
    "**Includes a consolidated results table + charts for each model.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b781e9",
   "metadata": {},
   "source": [
    "\n",
    "## Table of Contents\n",
    "1. Aim & Metrics (visuals)  \n",
    "2. Environment Snapshot (visuals)  \n",
    "3. Configuration (Paths, Target)  \n",
    "4. Load Data (first look)  \n",
    "5. Schema Overview (visuals)  \n",
    "6. Target Check & Distribution (visuals)  \n",
    "7. Missing Values Overview (visuals)  \n",
    "8. Numeric Features — Distributions & Pairplots (visuals)  \n",
    "9. Categorical Features — Top Levels & Proportions (visuals)  \n",
    "10. Correlation Heatmap & Scatter Matrix (visuals)  \n",
    "11. Train/Test Split & Class Balance (visuals)  \n",
    "12. Preprocessing Plan (impute/encode/scale) + Feature Type Counts (visuals)  \n",
    "13. Fit Preprocessor & Post‑Transform Checks (visuals)  \n",
    "14. SMOTE Demonstration on Training (visuals)  \n",
    "15. Baseline Models (LogReg, RandomForest) + Cross‑Validation (table + visuals)  \n",
    "16. Test‑Set Evaluation: Confusion, ROC, PR (visuals)  \n",
    "17. Threshold Sweep (visual)  \n",
    "18. Calibration Curve & Brier Score (visual)  \n",
    "19. Feature Importance (Random Forest) (visual)  \n",
    "20. Consolidated Results DataFrame + Metric Charts (table + visuals)  \n",
    "21. Notes for Scaling & Next Steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0005b2dd",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Aim & Metrics (visuals)\n",
    "Predict breast cancer risk using **non‑invasive** features.  \n",
    "Primary: **ROC‑AUC**. Also: **Recall**, **F1**, **PR‑AUC**.  \n",
    "The visuals below anchor the metric focus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b8a599",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "metrics = [\"ROC-AUC\",\"Recall\",\"F1\",\"PR-AUC\"]\n",
    "plt.figure()\n",
    "plt.bar(metrics, [1,1,1,1])\n",
    "plt.ylim(0,1.1); plt.title(\"Key metrics focus\"); plt.ylabel(\"Relative emphasis\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaaabbf",
   "metadata": {},
   "source": [
    "## 2) Environment Snapshot (visuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd6910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys, platform, importlib\n",
    "print(\"Python:\", sys.version.split()[0]); print(\"Platform:\", platform.platform())\n",
    "packages = [\"numpy\",\"pandas\",\"matplotlib\",\"scikit-learn\",\"imblearn\"]\n",
    "vers = []\n",
    "for p in packages:\n",
    "    try:\n",
    "        m = importlib.import_module(p if p!=\"scikit-learn\" else \"sklearn\")\n",
    "        vers.append(getattr(m,\"__version__\",\"n/a\"))\n",
    "    except Exception:\n",
    "        vers.append(\"not installed\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.bar(packages, [len(v) for v in vers])\n",
    "plt.title(\"Env snapshot — version string lengths\"); plt.xticks(rotation=45, ha=\"right\"); plt.tight_layout(); plt.show()\n",
    "\n",
    "for p,v in zip(packages, vers): print(f\"{p}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2fd9b5",
   "metadata": {},
   "source": [
    "## 3) Configuration (Paths, Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac04430",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_PATH = \"/mnt/data/sample_10percent.csv\"   # change to full dataset later\n",
    "TARGET_COL = \"cancer\"                          # set your actual label column\n",
    "TEST_SIZE = 0.2\n",
    "CV_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "N_JOBS = -1\n",
    "MAX_PLOT_ROWS = 60000\n",
    "\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "                             roc_curve, precision_recall_curve, average_precision_score, ConfusionMatrixDisplay, brier_score_loss)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 160)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "print(\"Configuration ready. TARGET_COL:\", TARGET_COL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c73030f",
   "metadata": {},
   "source": [
    "## 4) Load Data (first look)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03036a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head(5)); display(df.tail(3))\n",
    "_ = df.info(); display(pd.DataFrame(df.dtypes, columns=[\"dtype\"]).T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1fc08b",
   "metadata": {},
   "source": [
    "## 5) Schema Overview (visuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187978ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "schema_tbl = pd.DataFrame({\n",
    "    \"column\": df.columns,\n",
    "    \"dtype\": [str(t) for t in df.dtypes],\n",
    "    \"non_null\": [int(df[c].notna().sum()) for c in df.columns],\n",
    "    \"nulls\": [int(df[c].isna().sum()) for c in df.columns]\n",
    "})\n",
    "display(schema_tbl.head(40))\n",
    "\n",
    "plt.figure(); plt.barh(schema_tbl[\"column\"][:15], schema_tbl[\"non_null\"][:15]); plt.title(\"Top 15 by non-null\"); plt.tight_layout(); plt.show()\n",
    "plt.figure(); plt.barh(schema_tbl[\"column\"][:15], schema_tbl[\"nulls\"][:15]); plt.title(\"Top 15 by nulls\"); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5cb6c2",
   "metadata": {},
   "source": [
    "## 6) Target Check & Distribution (visuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1b4872",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert TARGET_COL in df.columns, f\"TARGET_COL '{TARGET_COL}' not found — set it in Config.\"\n",
    "vc = df[TARGET_COL].value_counts().sort_index()\n",
    "display(vc)\n",
    "plt.figure(); vc.plot(kind=\"bar\"); plt.title(\"Target distribution\"); plt.xlabel(TARGET_COL); plt.ylabel(\"Count\"); plt.show()\n",
    "display((vc/len(df)*100).round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2513fb57",
   "metadata": {},
   "source": [
    "## 7) Missing Values Overview (visuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26496296",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "miss = df.isna().sum().sort_values(ascending=False)\n",
    "miss_pct = (miss/len(df)*100).round(2)\n",
    "miss_tbl = pd.DataFrame({\"missing_count\": miss, \"missing_pct\": miss_pct})\n",
    "display(miss_tbl.head(40))\n",
    "\n",
    "plt.figure(); miss_tbl.head(20)[\"missing_pct\"].plot(kind=\"bar\"); plt.title(\"Top 20 missing %\"); plt.ylabel(\"%\"); plt.xticks(rotation=45, ha=\"right\"); plt.tight_layout(); plt.show()\n",
    "\n",
    "# Simple binary missingness heatmap for first 100 rows/cols (matplotlib only)\n",
    "r = min(100, len(df)); c = min(30, df.shape[1])\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.imshow(df.iloc[:r, :c].isna(), aspect=\"auto\")\n",
    "plt.title(\"Missingness heatmap (first 100 rows, 30 cols)\"); plt.xlabel(\"Columns\"); plt.ylabel(\"Rows\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Total NaNs:\", int(df.isna().sum().sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4462ff",
   "metadata": {},
   "source": [
    "## 8) Numeric Features — Distributions & Pairplots (visuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5241bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "plot_df = df if len(df)<=MAX_PLOT_ROWS else df.sample(MAX_PLOT_ROWS, random_state=RANDOM_STATE)\n",
    "\n",
    "for col in num_cols[:10]:\n",
    "    plt.figure(); plot_df[col].hist(bins=40); plt.title(f\"Distribution: {col}\"); plt.xlabel(col); plt.ylabel(\"Count\"); plt.show()\n",
    "\n",
    "# Pairwise scatter for first 3 numeric columns (quick view)\n",
    "if len(num_cols) >= 3 and TARGET_COL in df.columns:\n",
    "    first3 = num_cols[:3]\n",
    "    for i in range(3):\n",
    "        for j in range(i+1, 3):\n",
    "            plt.figure()\n",
    "            colors = df[TARGET_COL].map({0:0.2,1:0.8}) if df[TARGET_COL].dropna().isin([0,1]).all() else None\n",
    "            plt.scatter(plot_df[first3[i]], plot_df[first3[j]], s=5, alpha=0.5)\n",
    "            plt.xlabel(first3[i]); plt.ylabel(first3[j]); plt.title(f\"Scatter: {first3[i]} vs {first3[j]}\")\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1c5dcc",
   "metadata": {},
   "source": [
    "## 9) Categorical Features — Top Levels & Proportions (visuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63393066",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "for col in cat_cols[:8]:\n",
    "    counts = df[col].astype(str).value_counts().head(12)\n",
    "    plt.figure(); counts.plot(kind=\"bar\"); plt.title(f\"Top 12 levels: {col}\"); plt.xticks(rotation=45, ha=\"right\"); plt.tight_layout(); plt.show()\n",
    "    plt.figure(); (counts/counts.sum()).plot(kind=\"bar\"); plt.title(f\"Top 12 proportions: {col}\"); plt.xticks(rotation=45, ha=\"right\"); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a917738",
   "metadata": {},
   "source": [
    "## 10) Correlation Heatmap & Scatter Matrix (visuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f239dcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subset = num_cols[:12]\n",
    "if len(subset)>=2:\n",
    "    corr = df[subset].corr()\n",
    "    plt.figure(figsize=(8,6)); im = plt.imshow(corr, aspect=\"auto\"); plt.colorbar(im); plt.title(\"Correlation heatmap (subset)\")\n",
    "    plt.xticks(range(len(subset)), subset, rotation=90); plt.yticks(range(len(subset)), subset); plt.tight_layout(); plt.show()\n",
    "\n",
    "    # Simple scatter matrix (first 4 numeric columns)\n",
    "    sm_cols = num_cols[:4]\n",
    "    for i in range(len(sm_cols)):\n",
    "        for j in range(i+1, len(sm_cols)):\n",
    "            plt.figure(); plt.scatter(df[sm_cols[i]], df[sm_cols[j]], s=4, alpha=0.4)\n",
    "            plt.xlabel(sm_cols[i]); plt.ylabel(sm_cols[j]); plt.title(f\"Scatter: {sm_cols[i]} vs {sm_cols[j]}\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8f8813",
   "metadata": {},
   "source": [
    "## 11) Train/Test Split & Class Balance (visuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cda2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ID_COLUMNS = []\n",
    "X = df.drop(columns=[TARGET_COL]+[c for c in ID_COLUMNS if c in df.columns], errors=\"ignore\")\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y)\n",
    "print(\"Train:\", X_train.shape, \"| Test:\", X_test.shape)\n",
    "\n",
    "bal = pd.DataFrame({\"set\":[\"train\",\"test\"],\n",
    "                    \"positive_pct\":[float((y_train==1).mean()*100), float((y_test==1).mean()*100)]})\n",
    "plt.figure(); plt.bar(bal[\"set\"], bal[\"positive_pct\"]); plt.title(\"Positive % — train vs test\"); plt.ylabel(\"%\"); plt.ylim(0,100); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d69368b",
   "metadata": {},
   "source": [
    "## 12) Preprocessing Plan + Feature Type Counts (visuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631235bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "numeric_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())])\n",
    "categorical_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\")), (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))])\n",
    "\n",
    "preprocessor = ColumnTransformer([(\"num\", numeric_pipe, num_cols), (\"cat\", categorical_pipe, cat_cols)])\n",
    "\n",
    "plt.figure(); plt.bar([\"numeric\",\"categorical\"], [len(num_cols), len(cat_cols)]); plt.title(\"Feature type counts\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c259cf2f",
   "metadata": {},
   "source": [
    "## 13) Fit Preprocessor & Post‑Transform Checks (visuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b341a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Xt_train = preprocessor.fit_transform(X_train)\n",
    "Xt_test = preprocessor.transform(X_test)\n",
    "print(\"Transformed shapes:\", Xt_train.shape, Xt_test.shape)\n",
    "print(\"NaNs after preprocess (train)?\", bool(np.isnan(Xt_train).any()))\n",
    "print(\"NaNs after preprocess (test)?\", bool(np.isnan(Xt_test).any()))\n",
    "plt.figure(); plt.bar([\"train features\",\"test features\"], [Xt_train.shape[1], Xt_test.shape[1]]); plt.title(\"Transformed feature counts\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a0b01e",
   "metadata": {},
   "source": [
    "## 14) SMOTE Demonstration on Training (visuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eab3530",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sm = SMOTE(random_state=RANDOM_STATE)\n",
    "Xt_train_sm, y_train_sm = sm.fit_resample(Xt_train, y_train)\n",
    "\n",
    "before_pct = float((y_train==1).mean()*100); after_pct = float((y_train_sm==1).mean()*100)\n",
    "plt.figure(); plt.bar([\"before SMOTE\",\"after SMOTE\"], [before_pct, after_pct]); plt.ylabel(\"% positive\"); plt.title(\"Class balance (train)\"); plt.ylim(0,100); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d1c4bf",
   "metadata": {},
   "source": [
    "## 15) Baseline Models + Cross‑Validation (table + visuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e86e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scorer = {\"accuracy\":\"accuracy\",\"precision\":\"precision\",\"recall\":\"recall\",\"f1\":\"f1\",\"roc_auc\":\"roc_auc\",\"average_precision\":\"average_precision\"}\n",
    "cv = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "pipe_logreg = ImbPipeline([(\"prep\", preprocessor), (\"smote\", SMOTE(random_state=RANDOM_STATE)), (\"clf\", LogisticRegression(max_iter=1000, n_jobs=N_JOBS))])\n",
    "pipe_rf = ImbPipeline([(\"prep\", preprocessor), (\"smote\", SMOTE(random_state=RANDOM_STATE)), (\"clf\", RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE, n_jobs=N_JOBS))])\n",
    "\n",
    "models = {\"LogisticRegression\": pipe_logreg, \"RandomForest\": pipe_rf}\n",
    "\n",
    "cv_means = {}; cv_folds = {}\n",
    "for name, pipe in models.items():\n",
    "    scores = cross_validate(pipe, X_train, y_train, cv=cv, scoring=scorer, n_jobs=N_JOBS, return_estimator=False)\n",
    "    cv_means[name] = {m.replace(\"test_\",\"\"): float(np.mean(scores[m])) for m in scores if m.startswith(\"test_\")}\n",
    "    cv_folds[name] = {m.replace(\"test_\",\"\"): scores[m] for m in scores if m.startswith(\"test_\")}\n",
    "cv_df = pd.DataFrame(cv_means).T\n",
    "display(cv_df)\n",
    "\n",
    "# Per-metric bar chart (CV means)\n",
    "for metric in [\"roc_auc\",\"recall\",\"precision\",\"f1\",\"average_precision\",\"accuracy\"]:\n",
    "    if metric in cv_df.columns:\n",
    "        plt.figure(); plt.bar(cv_df.index, cv_df[metric]); plt.title(f\"CV mean — {metric}\"); plt.ylim(0,1); plt.show()\n",
    "\n",
    "# ROC-AUC boxplot across folds\n",
    "if \"roc_auc\" in cv_folds[\"LogisticRegression\"]:\n",
    "    data = [cv_folds[m][\"roc_auc\"] for m in models.keys()]\n",
    "    plt.figure(); plt.boxplot(data, labels=list(models.keys())); plt.title(\"CV ROC-AUC per fold\"); plt.ylim(0,1); plt.show()\n",
    "\n",
    "best_name = cv_df[\"roc_auc\"].idxmax()\n",
    "print(\"Best model by CV ROC‑AUC:\", best_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f9672",
   "metadata": {},
   "source": [
    "## 16) Test‑Set Evaluation: Confusion, ROC, PR (visuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8b74a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_pipe = models[best_name]\n",
    "best_pipe.fit(X_train, y_train)\n",
    "proba = best_pipe.predict_proba(X_test)[:,1]\n",
    "pred = (proba>=0.5).astype(int)\n",
    "\n",
    "test_results = {\n",
    "    \"accuracy\": accuracy_score(y_test, pred),\n",
    "    \"precision\": precision_score(y_test, pred, zero_division=0),\n",
    "    \"recall\": recall_score(y_test, pred, zero_division=0),\n",
    "    \"f1\": f1_score(y_test, pred, zero_division=0),\n",
    "    \"roc_auc\": roc_auc_score(y_test, proba),\n",
    "    \"average_precision\": average_precision_score(y_test, proba),\n",
    "}\n",
    "print(\"Test results:\", test_results)\n",
    "\n",
    "plt.figure(); ConfusionMatrixDisplay.from_predictions(y_test, pred); plt.title(f\"Confusion Matrix — {best_name}\"); plt.show()\n",
    "fpr,tpr,_ = roc_curve(y_test, proba); plt.figure(); plt.plot(fpr,tpr); plt.plot([0,1],[0,1],'--'); plt.title(\"ROC Curve\"); plt.show()\n",
    "prec,rec,_ = precision_recall_curve(y_test, proba); plt.figure(); plt.plot(rec,prec); plt.title(\"Precision‑Recall Curve\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00122150",
   "metadata": {},
   "source": [
    "## 17) Threshold Sweep (visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149ec06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "thresholds = np.linspace(0.1,0.9,9)\n",
    "accs=[]; recs=[]; precs=[]; f1s=[]\n",
    "for t in thresholds:\n",
    "    yhat = (proba>=t).astype(int)\n",
    "    accs.append(accuracy_score(y_test, yhat))\n",
    "    recs.append(recall_score(y_test, yhat, zero_division=0))\n",
    "    precs.append(precision_score(y_test, yhat, zero_division=0))\n",
    "    f1s.append(f1_score(y_test, yhat, zero_division=0))\n",
    "\n",
    "plt.figure(); plt.plot(thresholds,recs,label=\"Recall\"); plt.plot(thresholds,precs,label=\"Precision\"); plt.plot(thresholds,f1s,label=\"F1\")\n",
    "plt.title(\"Metric vs Threshold\"); plt.xlabel(\"Threshold\"); plt.ylabel(\"Score\"); plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c614204",
   "metadata": {},
   "source": [
    "## 18) Calibration Curve & Brier Score (visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5001eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bins = np.linspace(0.0, 1.0, 11)\n",
    "digitized = np.digitize(proba, bins)-1\n",
    "xs=[]; ys=[]\n",
    "for i in range(len(bins)-1):\n",
    "    mask = digitized==i\n",
    "    if mask.any():\n",
    "        xs.append(float(np.mean(proba[mask])))\n",
    "        ys.append(float(np.mean(y_test.iloc[mask])))\n",
    "plt.figure(); plt.plot(xs,ys,marker=\"o\"); plt.plot([0,1],[0,1],'--'); plt.title(\"Calibration curve\"); plt.xlabel(\"Avg predicted\"); plt.ylabel(\"Observed pos rate\"); plt.show()\n",
    "print(\"Brier score:\", brier_score_loss(y_test, proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bef41e",
   "metadata": {},
   "source": [
    "## 19) Feature Importance (Random Forest) (visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd51b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_pipe = ImbPipeline([(\"prep\", preprocessor), (\"smote\", SMOTE(random_state=RANDOM_STATE)), (\"clf\", RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE, n_jobs=N_JOBS))])\n",
    "rf_pipe.fit(X_train, y_train); rf = rf_pipe.named_steps[\"clf\"]\n",
    "if hasattr(rf,\"feature_importances_\"):\n",
    "    imp = rf.feature_importances_; topk=min(20,len(imp)); idx=np.argsort(imp)[-topk:][::-1]\n",
    "    plt.figure(figsize=(8,6)); plt.barh(range(topk), imp[idx][::-1]); plt.yticks(range(topk), [f\"feature_{i}\" for i in idx][::-1]); plt.title(\"RF top importances (indices)\"); plt.tight_layout(); plt.show()\n",
    "else:\n",
    "    print(\"No importances available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce14c425",
   "metadata": {},
   "source": [
    "## 20) Consolidated Results DataFrame + Metric Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bed80dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build a single results DataFrame combining CV means and Test metrics for each model\n",
    "results_rows = []\n",
    "for name, pipe in models.items():\n",
    "    # CV means already computed\n",
    "    row = {\"model\": name}\n",
    "    for m in [\"accuracy\",\"precision\",\"recall\",\"f1\",\"roc_auc\",\"average_precision\"]:\n",
    "        row[f\"cv_{m}\"] = float(pd.to_numeric(pd.Series(cv_folds[name][m])).mean())\n",
    "    results_rows.append(row)\n",
    "\n",
    "# Add test metrics for the chosen best model as well\n",
    "for k,v in test_results.items():\n",
    "    results_rows.append({\"model\": f\"{best_name}_TEST\", f\"cv_{k}\": float(v)})\n",
    "\n",
    "results_df = pd.DataFrame(results_rows).set_index(\"model\")\n",
    "display(results_df)\n",
    "\n",
    "# Visualize each metric across models\n",
    "for m in [\"cv_accuracy\",\"cv_precision\",\"cv_recall\",\"cv_f1\",\"cv_roc_auc\",\"cv_average_precision\"]:\n",
    "    if m in results_df.columns:\n",
    "        plt.figure(); results_df[m].plot(kind=\"bar\")\n",
    "        plt.title(f\"Results comparison — {m}\"); plt.ylim(0,1); plt.xticks(rotation=45, ha=\"right\"); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaafcb8",
   "metadata": {},
   "source": [
    "## 21) Notes for Scaling & Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e04dfe4",
   "metadata": {},
   "source": [
    "\n",
    "- Swap `DATA_PATH` to the full dataset; keep this structure.  \n",
    "- Decide threshold using the sweep to meet clinical recall targets.  \n",
    "- (Optional) Add tuning later and persist the final pipeline with `joblib`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
