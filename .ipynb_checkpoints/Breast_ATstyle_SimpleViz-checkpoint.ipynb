{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3a30f1d",
   "metadata": {},
   "source": [
    "\n",
    "# Early Breast Cancer Prediction — AT‑Style **Simple & Visual** (Procedural)\n",
    "\n",
    "**Updated:** 2025-08-08 21:28\n",
    "\n",
    "A long, step‑by‑step, **simple** notebook. No custom `def` functions, minimal logic,\n",
    "and **visualizations in every section**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfbc4bf",
   "metadata": {},
   "source": [
    "\n",
    "## Table of Contents\n",
    "1. Project Aim & Metrics  \n",
    "2. Environment Snapshot (with visual)  \n",
    "3. Configuration (Paths, Target)  \n",
    "4. Load Data (first look)  \n",
    "5. Schema Overview (data dictionary preview)  \n",
    "6. Target Check & Distribution (visual)  \n",
    "7. Missing Values Overview (visual)  \n",
    "8. Numeric Features — Distributions (visual)  \n",
    "9. Categorical Features — Top Levels (visual)  \n",
    "10. Correlation Heatmap (visual)  \n",
    "11. Train/Test Split (visual class balance)  \n",
    "12. Preprocessing Plan (impute/encode/scale)  \n",
    "13. Fit Preprocessor & Post‑Transform Checks (visual)  \n",
    "14. SMOTE Demonstration on Training (visual)  \n",
    "15. Baseline Models (LogReg, RandomForest) + Cross‑Validation (visual)  \n",
    "16. Test‑Set Evaluation: Confusion, ROC, PR (visual)  \n",
    "17. Threshold Sweep (visual)  \n",
    "18. Calibration Curve & Brier Score (visual)  \n",
    "19. Feature Importance (Random Forest) (visual)  \n",
    "20. Notes for Scaling & Next Steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f05137",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Project Aim & Metrics\n",
    "- Predict breast cancer risk from **non‑invasive** features only.  \n",
    "- Primary metric: **ROC‑AUC**; also track **Recall**, **F1**, and **PR‑AUC**.\n",
    "- Run on a 10% development sample, then scale to the full dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca199e4",
   "metadata": {},
   "source": [
    "## 2) Environment Snapshot (with visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e218173",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys, platform, importlib\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"Platform:\", platform.platform())\n",
    "\n",
    "packages = [\"numpy\",\"pandas\",\"matplotlib\",\"scikit-learn\",\"imblearn\"]\n",
    "versions = []\n",
    "for p in packages:\n",
    "    try:\n",
    "        m = importlib.import_module(p if p!=\"scikit-learn\" else \"sklearn\")\n",
    "        v = getattr(m, \"__version__\", \"n/a\")\n",
    "    except Exception:\n",
    "        v = \"not installed\"\n",
    "    versions.append(v)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.bar(packages, [len(s) for s in versions])\n",
    "plt.title(\"Environment snapshot — version string lengths (quick visual)\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for p,v in zip(packages, versions):\n",
    "    print(f\"{p}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a02fda2",
   "metadata": {},
   "source": [
    "## 3) Configuration (Paths, Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0d4f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_PATH = \"/mnt/data/sample_10percent.csv\"   # change to full dataset later\n",
    "TARGET_COL = \"cancer\"                          # set your actual label column\n",
    "TEST_SIZE = 0.2\n",
    "CV_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "N_JOBS = -1\n",
    "MAX_PLOT_ROWS = 60000\n",
    "\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "                             roc_curve, precision_recall_curve, average_precision_score, ConfusionMatrixDisplay)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 160)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "print(\"Configuration ready. TARGET_COL:\", TARGET_COL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a888f955",
   "metadata": {},
   "source": [
    "## 4) Load Data (first look)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b13a9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head(5))\n",
    "display(df.tail(3))\n",
    "_ = df.info()\n",
    "display(pd.DataFrame(df.dtypes, columns=[\"dtype\"]).T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb281a77",
   "metadata": {},
   "source": [
    "## 5) Schema Overview (data dictionary preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda2d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "schema_tbl = pd.DataFrame({\n",
    "    \"column\": df.columns,\n",
    "    \"dtype\": [str(t) for t in df.dtypes],\n",
    "    \"non_null\": [int(df[c].notna().sum()) for c in df.columns]\n",
    "})\n",
    "display(schema_tbl.head(30))\n",
    "\n",
    "plt.figure()\n",
    "plt.barh(schema_tbl[\"column\"][:15], schema_tbl[\"non_null\"][:15])\n",
    "plt.xlabel(\"Non-null count\"); plt.title(\"Top 15 columns by non-null count\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa81eaaf",
   "metadata": {},
   "source": [
    "## 6) Target Check & Distribution (visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e23ae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert TARGET_COL in df.columns, f\"TARGET_COL '{TARGET_COL}' not found — set it in Config.\"\n",
    "vc = df[TARGET_COL].value_counts().sort_index()\n",
    "display(vc)\n",
    "\n",
    "plt.figure()\n",
    "vc.plot(kind=\"bar\")\n",
    "plt.title(\"Target distribution\")\n",
    "plt.xlabel(TARGET_COL); plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Target distribution (%):\")\n",
    "display((vc/len(df)*100).round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc2ddcd",
   "metadata": {},
   "source": [
    "## 7) Missing Values Overview (visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c587db72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "missing_pct = (missing/len(df)*100).round(2)\n",
    "miss_tbl = pd.DataFrame({\"missing_count\": missing, \"missing_pct\": missing_pct})\n",
    "display(miss_tbl.head(30))\n",
    "\n",
    "plt.figure()\n",
    "miss_tbl.head(20)[\"missing_pct\"].plot(kind=\"bar\")\n",
    "plt.title(\"Top 20 columns by missing %\"); plt.ylabel(\"% missing\"); plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "print(\"Total NaNs in dataset:\", int(df.isna().sum().sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d66f24",
   "metadata": {},
   "source": [
    "## 8) Numeric Features — Distributions (visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02c1620",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "plot_df = df if len(df)<=MAX_PLOT_ROWS else df.sample(MAX_PLOT_ROWS, random_state=RANDOM_STATE)\n",
    "\n",
    "for col in num_cols[:8]:\n",
    "    plt.figure()\n",
    "    plot_df[col].hist(bins=40)\n",
    "    plt.title(f\"Distribution: {col}\"); plt.xlabel(col); plt.ylabel(\"Count\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745562bf",
   "metadata": {},
   "source": [
    "## 9) Categorical Features — Top Levels (visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316315bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "for col in cat_cols[:8]:\n",
    "    plt.figure()\n",
    "    df[col].astype(str).value_counts().head(15).plot(kind=\"bar\")\n",
    "    plt.title(f\"Top levels: {col}\"); plt.xlabel(col); plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45, ha=\"right\"); plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b83fdc4",
   "metadata": {},
   "source": [
    "## 10) Correlation Heatmap (visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798da987",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subset = num_cols[:15]\n",
    "if len(subset) >= 2:\n",
    "    corr = df[subset].corr()\n",
    "    plt.figure(figsize=(8,6))\n",
    "    im = plt.imshow(corr, aspect=\"auto\")\n",
    "    plt.colorbar(im)\n",
    "    plt.title(\"Correlation heatmap (subset)\")\n",
    "    plt.xticks(range(len(subset)), subset, rotation=90)\n",
    "    plt.yticks(range(len(subset)), subset)\n",
    "    plt.tight_layout(); plt.show()\n",
    "else:\n",
    "    print(\"Not enough numeric columns for a heatmap.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5700c67b",
   "metadata": {},
   "source": [
    "## 11) Train/Test Split (visual class balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b8c830",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ID_COLUMNS = []\n",
    "X = df.drop(columns=[TARGET_COL]+[c for c in ID_COLUMNS if c in df.columns], errors=\"ignore\")\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y)\n",
    "print(\"Train:\", X_train.shape, \"| Test:\", X_test.shape)\n",
    "\n",
    "bal = pd.DataFrame({\n",
    "    \"set\": [\"train\",\"test\"],\n",
    "    \"positive_pct\": [float((y_train==1).mean()*100), float((y_test==1).mean()*100)]\n",
    "})\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(bal[\"set\"], bal[\"positive_pct\"])\n",
    "plt.title(\"Positive class % — train vs test\")\n",
    "plt.ylabel(\"% positive\"); plt.ylim(0,100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eabc4c",
   "metadata": {},
   "source": [
    "## 12) Preprocessing Plan (impute/encode/scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b92ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "numeric_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                         (\"scaler\", StandardScaler())])\n",
    "categorical_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                             (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))])\n",
    "\n",
    "preprocessor = ColumnTransformer([(\"num\", numeric_pipe, num_cols),\n",
    "                                  (\"cat\", categorical_pipe, cat_cols)])\n",
    "\n",
    "print(\"Numerical features:\", len(num_cols), \"| Categorical features:\", len(cat_cols))\n",
    "plt.figure()\n",
    "plt.bar([\"numeric\",\"categorical\"], [len(num_cols), len(cat_cols)])\n",
    "plt.title(\"Feature types count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d73e0e",
   "metadata": {},
   "source": [
    "## 13) Fit Preprocessor & Post‑Transform Checks (visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6435e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Xt_train = preprocessor.fit_transform(X_train)\n",
    "Xt_test = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"Transformed shapes:\", Xt_train.shape, Xt_test.shape)\n",
    "print(\"Any NaNs after preprocess (train)?\", bool(np.isnan(Xt_train).any()))\n",
    "print(\"Any NaNs after preprocess (test)?\", bool(np.isnan(Xt_test).any()))\n",
    "\n",
    "sizes = [Xt_train.shape[1], Xt_test.shape[1]]\n",
    "plt.figure()\n",
    "plt.bar([\"train features\",\"test features\"], sizes)\n",
    "plt.title(\"Transformed feature counts\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a476e74f",
   "metadata": {},
   "source": [
    "## 14) SMOTE Demonstration on Training (visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d26ab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sm = SMOTE(random_state=RANDOM_STATE)\n",
    "Xt_train_demo, y_train_demo = sm.fit_resample(Xt_train, y_train)\n",
    "\n",
    "before_pct = float((y_train==1).mean()*100)\n",
    "after_pct = float((y_train_demo==1).mean()*100)\n",
    "\n",
    "plt.figure()\n",
    "plt.bar([\"before SMOTE\",\"after SMOTE\"], [before_pct, after_pct])\n",
    "plt.ylabel(\"% positive\"); plt.title(\"Training class balance — SMOTE demonstration\")\n",
    "plt.ylim(0,100); plt.show()\n",
    "\n",
    "print(\"Before SMOTE positive %:\", round(before_pct,2), \"| After SMOTE positive %:\", round(after_pct,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00b1f7",
   "metadata": {},
   "source": [
    "## 15) Baseline Models + Cross‑Validation (visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec02273",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scorer = {\"accuracy\":\"accuracy\",\"precision\":\"precision\",\"recall\":\"recall\",\"f1\":\"f1\",\"roc_auc\":\"roc_auc\",\"average_precision\":\"average_precision\"}\n",
    "cv = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "pipe_logreg = ImbPipeline([(\"prep\", preprocessor),\n",
    "                           (\"smote\", SMOTE(random_state=RANDOM_STATE)),\n",
    "                           (\"clf\", LogisticRegression(max_iter=1000, n_jobs=N_JOBS))])\n",
    "\n",
    "pipe_rf = ImbPipeline([(\"prep\", preprocessor),\n",
    "                       (\"smote\", SMOTE(random_state=RANDOM_STATE)),\n",
    "                       (\"clf\", RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE, n_jobs=N_JOBS))])\n",
    "\n",
    "models = {\"LogReg\": pipe_logreg, \"RF\": pipe_rf}\n",
    "\n",
    "cv_means = {}\n",
    "for name, pipe in models.items():\n",
    "    scores = cross_validate(pipe, X_train, y_train, cv=cv, scoring=scorer, n_jobs=N_JOBS)\n",
    "    cv_means[name] = {m: float(np.mean(scores[m])) for m in scores if m.startswith(\"test_\")}\n",
    "\n",
    "cv_df = pd.DataFrame(cv_means).T\n",
    "display(cv_df)\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(cv_df.index, cv_df[\"test_roc_auc\"])\n",
    "plt.title(\"CV ROC‑AUC by model\")\n",
    "plt.ylabel(\"ROC‑AUC\")\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n",
    "\n",
    "best_name = cv_df[\"test_roc_auc\"].idxmax()\n",
    "print(\"Best model by CV ROC‑AUC:\", best_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7fea8f",
   "metadata": {},
   "source": [
    "## 16) Test‑Set Evaluation: Confusion, ROC, PR (visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f911e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_pipe = models[best_name]\n",
    "best_pipe.fit(X_train, y_train)\n",
    "\n",
    "proba = best_pipe.predict_proba(X_test)[:,1]\n",
    "pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
    "print(\"Precision:\", precision_score(y_test, pred, zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, pred, zero_division=0))\n",
    "print(\"F1:\", f1_score(y_test, pred, zero_division=0))\n",
    "print(\"ROC‑AUC:\", roc_auc_score(y_test, proba))\n",
    "print(\"PR‑AUC:\", average_precision_score(y_test, proba))\n",
    "\n",
    "plt.figure()\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, pred)\n",
    "plt.title(f\"Confusion Matrix — {best_name}\")\n",
    "plt.show()\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr); plt.plot([0,1],[0,1],'--')\n",
    "plt.title(\"ROC Curve\"); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\")\n",
    "plt.show()\n",
    "\n",
    "prec, rec, _ = precision_recall_curve(y_test, proba)\n",
    "plt.figure()\n",
    "plt.plot(rec, prec)\n",
    "plt.title(\"Precision‑Recall Curve\"); plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd5384e",
   "metadata": {},
   "source": [
    "## 17) Threshold Sweep (visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e27696",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "thresholds = np.linspace(0.1, 0.9, 9)\n",
    "accs, recs, precs, f1s = [], [], [], []\n",
    "for t in thresholds:\n",
    "    yhat = (proba >= t).astype(int)\n",
    "    accs.append(accuracy_score(y_test, yhat))\n",
    "    recs.append(recall_score(y_test, yhat, zero_division=0))\n",
    "    precs.append(precision_score(y_test, yhat, zero_division=0))\n",
    "    f1s.append(f1_score(y_test, yhat, zero_division=0))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(thresholds, recs, label=\"Recall\")\n",
    "plt.plot(thresholds, precs, label=\"Precision\")\n",
    "plt.plot(thresholds, f1s, label=\"F1\")\n",
    "plt.title(\"Metric vs Threshold\")\n",
    "plt.xlabel(\"Threshold\"); plt.ylabel(\"Score\"); plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efbe32c",
   "metadata": {},
   "source": [
    "## 18) Calibration Curve & Brier Score (visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b3245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bins = np.linspace(0.0, 1.0, 11)\n",
    "digitized = np.digitize(proba, bins) - 1\n",
    "xs, ys = [], []\n",
    "for i in range(len(bins)-1):\n",
    "    mask = digitized == i\n",
    "    if mask.any():\n",
    "        xs.append(float(np.mean(proba[mask])))\n",
    "        ys.append(float(np.mean(y_test.iloc[mask])))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(xs, ys, marker=\"o\")\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.title(\"Calibration curve\"); plt.xlabel(\"Avg predicted\"); plt.ylabel(\"Observed positive rate\")\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import brier_score_loss\n",
    "print(\"Brier score:\", brier_score_loss(y_test, proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f6ce7f",
   "metadata": {},
   "source": [
    "## 19) Feature Importance (Random Forest) (visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7748a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_pipe = ImbPipeline([(\"prep\", preprocessor),\n",
    "                       (\"smote\", SMOTE(random_state=RANDOM_STATE)),\n",
    "                       (\"clf\", RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE, n_jobs=N_JOBS))])\n",
    "rf_pipe.fit(X_train, y_train)\n",
    "rf = rf_pipe.named_steps[\"clf\"]\n",
    "\n",
    "if hasattr(rf, \"feature_importances_\"):\n",
    "    importances = rf.feature_importances_\n",
    "    topk = min(20, len(importances))\n",
    "    idx = np.argsort(importances)[-topk:][::-1]\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.barh(range(topk), importances[idx][::-1])\n",
    "    plt.yticks(range(topk), [f\"feature_{i}\" for i in idx][::-1])\n",
    "    plt.title(\"Random Forest — Top feature importances (indices)\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "else:\n",
    "    print(\"RandomForestClassifier importances not available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c960a841",
   "metadata": {},
   "source": [
    "## 20) Notes for Scaling & Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f228e038",
   "metadata": {},
   "source": [
    "\n",
    "- Switch `DATA_PATH` to the **full dataset** and re‑run end‑to‑end.  \n",
    "- Keep the model set small for clarity (LogReg + RF).  \n",
    "- If runtime allows, add tuning later; save the final pipeline with `joblib`.  \n",
    "- Decide on a clinical operating threshold using the threshold sweep.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
