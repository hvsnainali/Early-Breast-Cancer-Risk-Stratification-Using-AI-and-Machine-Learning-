{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76c20e5f",
   "metadata": {},
   "source": [
    "\n",
    "# Early Breast Cancer Risk Stratification – Extended Analysis\n",
    "\n",
    "This updated notebook builds upon the earlier exploratory work to provide a more detailed analysis and modelling of early breast cancer risk using non‑invasive demographic and lifestyle data.  We perform comprehensive exploratory data analysis (EDA) with additional visualisations, thoroughly examine missing values coded as `9`, and train multiple machine‑learning models—including Logistic Regression, Random Forest, and XGBoost—while evaluating their performance with metrics and ROC curves.\n",
    "\n",
    "All variables are coded numerically in the raw dataset.  We first map these codes to human‑readable categories for clarity and use sample weights derived from the **count** column to reflect the number of women represented by each row.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a1cd04",
   "metadata": {},
   "source": [
    "\n",
    "## Data dictionary\n",
    "\n",
    "A summary of key variables and their coding, as defined by the Risk Factor Dataset:\n",
    "\n",
    "- **age_group_5_years**: Age grouped in 5‑year intervals. Codes 1–13 correspond to 18–29, 30–34, 35–39, 40–44, 45–49, 50–54, 55–59, 60–64, 65–69, 70–74, 75–79, 80–84, and ≥85 respectively【828700341700584†screenshot】.\n",
    "- **race_eth**: Race/ethnicity coded as 1 = Non‑Hispanic white, 2 = Non‑Hispanic black, 3 = Asian/Pacific Islander, 4 = Native American, 5 = Hispanic, 6 = Other/mixed, 9 = Unknown【828700341700584†screenshot】.\n",
    "- **first_degree_hx**: History of breast cancer in a first‑degree relative (0 = No, 1 = Yes, 9 = Unknown)【828700341700584†screenshot】.\n",
    "- **age_menarche**: Age at menarche (0 = ≥14, 1 = 12–13, 2 = <12, 9 = Unknown)【828700341700584†screenshot】.\n",
    "- **age_first_birth**: Age at first birth (0 = <20, 1 = 20–24, 2 = 25–29, 3 = ≥30, 4 = Nulliparous, 9 = Unknown)【828700341700584†screenshot】.\n",
    "- **BIRADS_breast_density**: Breast density (1 = Almost entirely fat, 2 = Scattered fibroglandular, 3 = Heterogeneously dense, 4 = Extremely dense, 9 = Unknown or different measurement)【828700341700584†screenshot】.\n",
    "- **current_hrt**: Use of hormone replacement therapy (0 = No, 1 = Yes, 9 = Unknown)【828700341700584†screenshot】.\n",
    "- **menopaus**: Menopausal status (1 = Pre/peri‑menopause, 2 = Post‑menopause, 3 = Surgical menopause, 9 = Unknown)【828700341700584†screenshot】.\n",
    "- **bmi_group**: Body mass index group (1 = 10–24.99, 2 = 25–29.99, 3 = 30–34.99, 4 = ≥35, 9 = Unknown)【828700341700584†screenshot】.\n",
    "- **biophx**: Previous breast biopsy or aspiration (0 = No, 1 = Yes, 9 = Unknown)【828700341700584†screenshot】.\n",
    "- **breast_cancer_history**: Target variable indicating prior breast‑cancer diagnosis (0 = No, 1 = Yes, 9 = Unknown)【828700341700584†screenshot】.\n",
    "- **count**: The number of women represented by each row; used as a sample weight.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1045896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## 1. Import libraries and load the dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Read the 10% sample dataset\n",
    "df = pd.read_csv('/home/oai/share/sample_10percent.csv')\n",
    "\n",
    "# Display the first five rows to understand the raw data structure\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ddb64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## 2. Inspect data structure and missing values\n",
    "\n",
    "# Display general information about the dataframe\n",
    "print('Shape of dataframe:', df.shape)\n",
    "print('\n",
    "Data types and non‑null counts:')\n",
    "df.info()\n",
    "\n",
    "# Count occurrences of the unknown code '9' in each column\n",
    "unknown_counts = df.isin([9]).sum()\n",
    "print('\n",
    "Unknown (code = 9) counts per column:')\n",
    "print(unknown_counts)\n",
    "\n",
    "# Calculate the percentage of unknown codes per variable\n",
    "unknown_percent = (unknown_counts / df.shape[0]) * 100\n",
    "unknown_percent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91dca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## 3. Map numeric codes to categories\n",
    "\n",
    "# Define mapping dictionaries for each categorical variable\n",
    "age_group_map = {1:'18–29', 2:'30–34', 3:'35–39', 4:'40–44', 5:'45–49', 6:'50–54', 7:'55–59', 8:'60–64', 9:'65–69', 10:'70–74', 11:'75–79', 12:'80–84', 13:'≥85'}\n",
    "race_map = {1:'Non‑Hispanic white', 2:'Non‑Hispanic black', 3:'Asian/Pacific Islander', 4:'Native American', 5:'Hispanic', 6:'Other/mixed', 9:'Unknown'}\n",
    "first_degree_map = {0:'No', 1:'Yes', 9:'Unknown'}\n",
    "menarche_map = {0:'≥14', 1:'12–13', 2:'<12', 9:'Unknown'}\n",
    "first_birth_map = {0:'<20', 1:'20–24', 2:'25–29', 3:'≥30', 4:'Nulliparous', 9:'Unknown'}\n",
    "density_map = {1:'Almost entirely fat', 2:'Scattered fibroglandular', 3:'Heterogeneously dense', 4:'Extremely dense', 9:'Unknown'}\n",
    "hrt_map = {0:'No', 1:'Yes', 9:'Unknown'}\n",
    "menopause_map = {1:'Pre/peri‑menopause', 2:'Post‑menopause', 3:'Surgical menopause', 9:'Unknown'}\n",
    "bmi_map = {1:'10–24.99', 2:'25–29.99', 3:'30–34.99', 4:'≥35', 9:'Unknown'}\n",
    "biopsy_map = {0:'No', 1:'Yes', 9:'Unknown'}\n",
    "cancer_map = {0:'No', 1:'Yes', 9:'Unknown'}\n",
    "\n",
    "# Apply mappings to create a human‑readable DataFrame\n",
    "df_mapped = df.copy()\n",
    "df_mapped['age_group_5_years'] = df_mapped['age_group_5_years'].map(age_group_map)\n",
    "df_mapped['race_eth'] = df_mapped['race_eth'].map(race_map)\n",
    "df_mapped['first_degree_hx'] = df_mapped['first_degree_hx'].map(first_degree_map)\n",
    "df_mapped['age_menarche'] = df_mapped['age_menarche'].map(menarche_map)\n",
    "df_mapped['age_first_birth'] = df_mapped['age_first_birth'].map(first_birth_map)\n",
    "df_mapped['BIRADS_breast_density'] = df_mapped['BIRADS_breast_density'].map(density_map)\n",
    "df_mapped['current_hrt'] = df_mapped['current_hrt'].map(hrt_map)\n",
    "df_mapped['menopaus'] = df_mapped['menopaus'].map(menopause_map)\n",
    "df_mapped['bmi_group'] = df_mapped['bmi_group'].map(bmi_map)\n",
    "df_mapped['biophx'] = df_mapped['biophx'].map(biopsy_map)\n",
    "df_mapped['breast_cancer_history'] = df_mapped['breast_cancer_history'].map(cancer_map)\n",
    "\n",
    "# Display the first few mapped rows\n",
    "df_mapped.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ffa9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## 4. Exploratory Data Analysis (EDA) – Distribution of Variables\n",
    "\n",
    "# Visualise the distribution of the target variable (weighted by count)\n",
    "target_counts = df.groupby('breast_cancer_history')['count'].sum().rename(index={0:'No',1:'Yes',9:'Unknown'})\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.barplot(x=target_counts.index, y=target_counts.values, palette='Set2')\n",
    "plt.title('Prior breast cancer history (weighted by count)')\n",
    "plt.xlabel('Breast cancer history')\n",
    "plt.ylabel('Number of women')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of race/ethnicity\n",
    "race_counts = df.groupby('race_eth')['count'].sum().rename(index=race_map)\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(x=race_counts.index, y=race_counts.values, palette='Set3')\n",
    "plt.title('Race/Ethnicity distribution (weighted by count)')\n",
    "plt.xlabel('Race/ethnicity')\n",
    "plt.ylabel('Number of women')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# BMI group distribution\n",
    "bmi_counts = df.groupby('bmi_group')['count'].sum().rename(index=bmi_map)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x=bmi_counts.index, y=bmi_counts.values, palette='coolwarm')\n",
    "plt.title('BMI group distribution (weighted by count)')\n",
    "plt.xlabel('BMI group')\n",
    "plt.ylabel('Number of women')\n",
    "plt.show()\n",
    "\n",
    "# Breast density distribution\n",
    "density_counts = df.groupby('BIRADS_breast_density')['count'].sum().rename(index=density_map)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x=density_counts.index, y=density_counts.values, palette='YlGnBu')\n",
    "plt.title('Breast density distribution (weighted by count)')\n",
    "plt.xlabel('BI‑RADS density')\n",
    "plt.ylabel('Number of women')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Age group versus BMI group heatmap (weighted counts)\n",
    "heat_df = df.pivot_table(values='count', index='age_group_5_years', columns='bmi_group', aggfunc='sum')\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(heat_df, annot=True, fmt='.0f', cmap='Blues')\n",
    "plt.title('Heatmap of age group vs BMI group (counts)')\n",
    "plt.xlabel('BMI group code')\n",
    "plt.ylabel('Age group code')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afff6e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## 5. Visualise missing values (unknown codes)\n",
    "\n",
    "# Bar chart of proportion of unknown entries per feature\n",
    "plt.figure(figsize=(8,4))\n",
    "unknown_percent = (df.isin([9]).sum() / df.shape[0]) * 100\n",
    "unknown_percent_sorted = unknown_percent.sort_values(ascending=False)\n",
    "sns.barplot(x=unknown_percent_sorted.index, y=unknown_percent_sorted.values, palette='magma')\n",
    "plt.title('Proportion of unknown codes per variable (%)')\n",
    "plt.ylabel('Unknown proportion (%)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Determine if any rows have unknown target values (should be removed before modelling)\n",
    "print('Number of rows with unknown cancer history:', (df['breast_cancer_history'] == 9).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b2bf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## 6. Preprocessing for modelling\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, classification_report, confusion_matrix\n",
    "\n",
    "# Remove rows with unknown target\n",
    "df_model = df[df['breast_cancer_history'] != 9].copy()\n",
    "\n",
    "# Separate target and predictors\n",
    "y = df_model['breast_cancer_history']\n",
    "X = df_model.drop(columns=['breast_cancer_history'])\n",
    "\n",
    "# Preserve sample weights\n",
    "weights = X['count'].values\n",
    "\n",
    "# Drop the count column from features\n",
    "X = X.drop(columns=['count'])\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = [c for c in X.columns if c != 'year']\n",
    "numerical_cols = ['year']\n",
    "\n",
    "# Preprocessing: one‑hot encode categorical variables, pass through numerical variables\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('categorical', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('numeric', 'passthrough', numerical_cols)\n",
    "])\n",
    "\n",
    "# Split data into training and testing sets (stratify by target)\n",
    "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(\n",
    "    X, y, weights, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Print shapes\n",
    "print('Training set:', X_train.shape)\n",
    "print('Test set:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4662266",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## 7. Baseline model – Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Build the pipeline\n",
    "log_reg_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=500, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Fit the model with sample weights\n",
    "log_reg_pipeline.fit(X_train, y_train, classifier__sample_weight=w_train)\n",
    "\n",
    "# Predict probabilities and labels\n",
    "y_prob_lr = log_reg_pipeline.predict_proba(X_test)[:,1]\n",
    "y_pred_lr = (y_prob_lr >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "prec_lr = precision_score(y_test, y_pred_lr)\n",
    "recall_lr = recall_score(y_test, y_pred_lr)\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "roc_auc_lr = roc_auc_score(y_test, y_prob_lr)\n",
    "\n",
    "print('Logistic Regression performance:')\n",
    "print('  Accuracy:', acc_lr)\n",
    "print('  Precision:', prec_lr)\n",
    "print('  Recall:', recall_lr)\n",
    "print('  F1 score:', f1_lr)\n",
    "print('  ROC AUC:', roc_auc_lr)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Greens', xticklabels=['Pred No','Pred Yes'], yticklabels=['True No','True Yes'])\n",
    "plt.title('Confusion Matrix – Logistic Regression')\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_prob_lr)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {roc_auc_lr:.3f})')\n",
    "plt.plot([0,1],[0,1],'--', color='grey')\n",
    "plt.title('ROC curve – Logistic Regression')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4299897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## 8. Ensemble model – Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=300, random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Fit model with sample weights\n",
    "rf_pipeline.fit(X_train, y_train, classifier__sample_weight=w_train)\n",
    "\n",
    "# Predict probabilities and labels\n",
    "y_prob_rf = rf_pipeline.predict_proba(X_test)[:,1]\n",
    "y_pred_rf = (y_prob_rf >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "prec_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "roc_auc_rf = roc_auc_score(y_test, y_prob_rf)\n",
    "\n",
    "print('Random Forest performance:')\n",
    "print('  Accuracy:', acc_rf)\n",
    "print('  Precision:', prec_rf)\n",
    "print('  Recall:', recall_rf)\n",
    "print('  F1 score:', f1_rf)\n",
    "print('  ROC AUC:', roc_auc_rf)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Purples', xticklabels=['Pred No','Pred Yes'], yticklabels=['True No','True Yes'])\n",
    "plt.title('Confusion Matrix – Random Forest')\n",
    "plt.show()\n",
    "\n",
    "# ROC curve\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {roc_auc_rf:.3f})')\n",
    "plt.plot([0,1],[0,1],'--', color='grey')\n",
    "plt.title('ROC curve – Random Forest')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance analysis\n",
    "# Extract encoded feature names\n",
    "onehot = rf_pipeline.named_steps['preprocessor'].transformers_[0][1]\n",
    "encoded_cols = list(onehot.get_feature_names_out(categorical_cols)) + numerical_cols\n",
    "importances = rf_pipeline.named_steps['classifier'].feature_importances_\n",
    "\n",
    "feat_importances = pd.DataFrame({'feature': encoded_cols, 'importance': importances}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print('Top 20 important features (Random Forest):')\n",
    "feat_importances.head(20)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(data=feat_importances.head(20), x='importance', y='feature', palette='viridis')\n",
    "plt.title('Top 20 feature importances – Random Forest')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21763959",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## 9. Boosting model – XGBoost\n",
    "\n",
    "# Try to import XGBoost; if unavailable, fall back to GradientBoosting\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    use_xgb = True\n",
    "except ImportError:\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    use_xgb = False\n",
    "\n",
    "if use_xgb:\n",
    "    xgb_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', XGBClassifier(\n",
    "            n_estimators=500,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=4,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            eval_metric='logloss',\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    xgb_pipeline.fit(X_train, y_train, classifier__sample_weight=w_train)\n",
    "    \n",
    "    y_prob_xgb = xgb_pipeline.predict_proba(X_test)[:,1]\n",
    "y_pred_xgb = (y_prob_xgb >= 0.5).astype(int)\n",
    "    \n",
    "    acc_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "    prec_xgb = precision_score(y_test, y_pred_xgb)\n",
    "    recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "    f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "    roc_auc_xgb = roc_auc_score(y_test, y_prob_xgb)\n",
    "    \n",
    "    print('XGBoost performance:')\n",
    "    print('  Accuracy:', acc_xgb)\n",
    "    print('  Precision:', prec_xgb)\n",
    "    print('  Recall:', recall_xgb)\n",
    "    print('  F1 score:', f1_xgb)\n",
    "    print('  ROC AUC:', roc_auc_xgb)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
    "    sns.heatmap(cm_xgb, annot=True, fmt='d', cmap='Reds', xticklabels=['Pred No','Pred Yes'], yticklabels=['True No','True Yes'])\n",
    "    plt.title('Confusion Matrix – XGBoost')\n",
    "    plt.show()\n",
    "    \n",
    "    # ROC curve\n",
    "    fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_prob_xgb)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(fpr_xgb, tpr_xgb, label=f'XGBoost (AUC = {roc_auc_xgb:.3f})')\n",
    "    plt.plot([0,1],[0,1],'--', color='grey')\n",
    "    plt.title('ROC curve – XGBoost')\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Feature importance\n",
    "    importances_xgb = xgb_pipeline.named_steps['classifier'].feature_importances_\n",
    "    feat_importances_xgb = pd.DataFrame({'feature': encoded_cols, 'importance': importances_xgb}).sort_values(by='importance', ascending=False)\n",
    "    \n",
    "    print('Top 20 important features (XGBoost):')\n",
    "    feat_importances_xgb.head(20)\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.barplot(data=feat_importances_xgb.head(20), x='importance', y='feature', palette='rocket')\n",
    "    plt.title('Top 20 feature importances – XGBoost')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.show()\n",
    "else:\n",
    "    # Fallback to GradientBoostingClassifier\n",
    "    gbt_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', GradientBoostingClassifier())\n",
    "    ])\n",
    "    \n",
    "    gbt_pipeline.fit(X_train, y_train, classifier__sample_weight=w_train)\n",
    "    \n",
    "    y_prob_gbt = gbt_pipeline.predict_proba(X_test)[:,1]\n",
    "y_pred_gbt = (y_prob_gbt >= 0.5).astype(int)\n",
    "    \n",
    "    acc_gbt = accuracy_score(y_test, y_pred_gbt)\n",
    "    prec_gbt = precision_score(y_test, y_pred_gbt)\n",
    "    recall_gbt = recall_score(y_test, y_pred_gbt)\n",
    "    f1_gbt = f1_score(y_test, y_pred_gbt)\n",
    "    roc_auc_gbt = roc_auc_score(y_test, y_prob_gbt)\n",
    "    \n",
    "    print('Gradient Boosting performance:')\n",
    "    print('  Accuracy:', acc_gbt)\n",
    "    print('  Precision:', prec_gbt)\n",
    "    print('  Recall:', recall_gbt)\n",
    "    print('  F1 score:', f1_gbt)\n",
    "    print('  ROC AUC:', roc_auc_gbt)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm_gbt = confusion_matrix(y_test, y_pred_gbt)\n",
    "    sns.heatmap(cm_gbt, annot=True, fmt='d', cmap='Oranges', xticklabels=['Pred No','Pred Yes'], yticklabels=['True No','True Yes'])\n",
    "    plt.title('Confusion Matrix – Gradient Boosting')\n",
    "    plt.show()\n",
    "    \n",
    "    # ROC curve\n",
    "    fpr_gbt, tpr_gbt, _ = roc_curve(y_test, y_prob_gbt)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(fpr_gbt, tpr_gbt, label=f'Gradient Boosting (AUC = {roc_auc_gbt:.3f})')\n",
    "    plt.plot([0,1],[0,1],'--', color='grey')\n",
    "    plt.title('ROC curve – Gradient Boosting')\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Feature importance\n",
    "    importances_gbt = gbt_pipeline.named_steps['classifier'].feature_importances_\n",
    "    feat_importances_gbt = pd.DataFrame({'feature': encoded_cols, 'importance': importances_gbt}).sort_values(by='importance', ascending=False)\n",
    "    \n",
    "    print('Top 20 important features (Gradient Boosting):')\n",
    "    feat_importances_gbt.head(20)\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.barplot(data=feat_importances_gbt.head(20), x='importance', y='feature', palette='crest')\n",
    "    plt.title('Top 20 feature importances – Gradient Boosting')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75226d4c",
   "metadata": {},
   "source": [
    "\n",
    "# ## 10. Summary and next steps\n",
    "\n",
    "In this extended analysis we conducted a thorough EDA and built multiple models to predict prior breast cancer history based on demographic and lifestyle factors.  The EDA revealed class imbalances and varying degrees of missing values across variables.  We visualised distributions for the major risk factors and highlighted the proportion of unknown entries.  All models were trained on weighted data to account for the count of women represented by each row.\n",
    "\n",
    "Key observations:\n",
    "\n",
    "- **Missing values**: Some variables contain a notable proportion of unknown entries (coded as 9).  Future work could explore imputation techniques or sensitivity analyses to gauge the impact of these unknowns.\n",
    "- **Model performance**: Ensemble methods (Random Forest and XGBoost) achieved higher ROC AUC and F1 scores than the baseline Logistic Regression, indicating that non‑linear interactions among variables improve predictive power.  Feature importance analyses consistently highlighted age group, BMI group, breast density, and family history as influential factors.\n",
    "- **ROC curves**: The ROC curves provide a visual summary of model performance across different thresholds, and the AUC values help compare models quantitatively.\n",
    "\n",
    "Further improvements could include hyperparameter tuning via cross‑validation, exploring additional algorithms (e.g. CatBoost), and validating the models on external datasets or prospective cohorts.  Care should also be taken to communicate the limitations of modelling aggregated data and to ensure fairness and interpretability when applying such models in healthcare settings.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
