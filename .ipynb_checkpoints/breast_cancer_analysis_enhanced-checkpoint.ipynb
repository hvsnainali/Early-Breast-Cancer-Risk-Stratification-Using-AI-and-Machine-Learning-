{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3363ec6",
   "metadata": {},
   "source": [
    "\n",
    "# Early Breast Cancer Risk Stratification – Hyperparameter Tuning and Additional Algorithms\n",
    "\n",
    "This notebook extends the previous analyses by incorporating hyperparameter tuning via cross‑validation and experimenting with an additional algorithm, CatBoost, which is well suited for categorical data.  We also discuss the limitations of modelling aggregated data and issues related to fairness and interpretability.  The dataset and variable descriptions remain the same as before【828700341700584†screenshot】.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266e355d",
   "metadata": {},
   "source": [
    "\n",
    "## Overview\n",
    "\n",
    "We use the same dataset of 150 k rows representing a 10 % sample of the original risk‑factor cohort.  Variables encode demographic, reproductive and lifestyle factors using integer codes (see previous section for details).  Each row summarises a group of women with identical covariate profiles and a corresponding `count` indicating how many individuals the row represents【828700341700584†screenshot】.\n",
    "\n",
    "The target variable `breast_cancer_history` is binary (0 = No, 1 = Yes; rows with code 9 are removed before modelling).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03056ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## 1. Load data and define mappings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Read dataset\n",
    "df = pd.read_csv('/home/oai/share/sample_10percent.csv')\n",
    "\n",
    "# Remove rows with unknown target\n",
    "df = df[df['breast_cancer_history'] != 9].copy()\n",
    "\n",
    "# Define categorical and numerical columns\n",
    "categorical_cols = [col for col in df.columns if col not in ['year', 'count', 'breast_cancer_history']]\n",
    "numerical_cols = ['year']\n",
    "\n",
    "# Sample weights and target\n",
    "sample_weights = df['count'].values\n",
    "y = df['breast_cancer_history']\n",
    "X = df.drop(columns=['breast_cancer_history', 'count'])\n",
    "\n",
    "# Preprocessor for all models\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('categorical', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('numeric', 'passthrough', numerical_cols)\n",
    "])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(\n",
    "    X, y, sample_weights, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Print basic shapes\n",
    "print('Train shape:', X_train.shape)\n",
    "print('Test shape:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d47110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## 2. Hyperparameter tuning – Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define pipeline\n",
    "lr_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Define hyperparameter grid for C (inverse regularisation strength) and penalty\n",
    "param_grid_lr = {\n",
    "    'classifier__C': [0.01, 0.1, 1, 10],\n",
    "    'classifier__penalty': ['l2'],\n",
    "    'classifier__solver': ['lbfgs']\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV with 3‑fold cross‑validation; scoring by F1 because of imbalance\n",
    "grid_lr = GridSearchCV(lr_pipeline, param_grid_lr, cv=3, scoring='f1', n_jobs=-1, verbose=0)\n",
    "\n",
    "# Fit grid search\n",
    "grid_lr.fit(X_train, y_train, classifier__sample_weight=w_train)\n",
    "\n",
    "print('Best hyperparameters for Logistic Regression:', grid_lr.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_lr = grid_lr.best_estimator_\n",
    "\n",
    "y_prob_lr = best_lr.predict_proba(X_test)[:,1]\n",
    "y_pred_lr = (y_prob_lr >= 0.5).astype(int)\n",
    "\n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "prec_lr = precision_score(y_test, y_pred_lr)\n",
    "recall_lr = recall_score(y_test, y_pred_lr)\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "roc_auc_lr = roc_auc_score(y_test, y_prob_lr)\n",
    "\n",
    "print('Tuned Logistic Regression performance:')\n",
    "print('  Accuracy:', acc_lr)\n",
    "print('  Precision:', prec_lr)\n",
    "print('  Recall:', recall_lr)\n",
    "print('  F1 score:', f1_lr)\n",
    "print('  ROC AUC:', roc_auc_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bdce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## 3. Hyperparameter tuning – Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Pipeline\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Hyperparameter distribution\n",
    "param_distributions_rf = {\n",
    "    'classifier__n_estimators': [200, 300, 400, 500],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "# Randomised search with 3‑fold cross‑validation; limit iterations for efficiency\n",
    "rand_rf = RandomizedSearchCV(rf_pipeline, param_distributions_rf, n_iter=10, cv=3, scoring='f1', random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit search\n",
    "rand_rf.fit(X_train, y_train, classifier__sample_weight=w_train)\n",
    "\n",
    "print('Best hyperparameters for Random Forest:', rand_rf.best_params_)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_rf = rand_rf.best_estimator_\n",
    "y_prob_rf = best_rf.predict_proba(X_test)[:,1]\n",
    "y_pred_rf = (y_prob_rf >= 0.5).astype(int)\n",
    "\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "prec_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "roc_auc_rf = roc_auc_score(y_test, y_prob_rf)\n",
    "\n",
    "print('Tuned Random Forest performance:')\n",
    "print('  Accuracy:', acc_rf)\n",
    "print('  Precision:', prec_rf)\n",
    "print('  Recall:', recall_rf)\n",
    "print('  F1 score:', f1_rf)\n",
    "print('  ROC AUC:', roc_auc_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d519f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## 4. Hyperparameter tuning – XGBoost\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    use_xgb = True\n",
    "except ImportError:\n",
    "    use_xgb = False\n",
    "\n",
    "if use_xgb:\n",
    "    xgb_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', XGBClassifier(eval_metric='logloss', random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Parameter distributions\n",
    "    param_dist_xgb = {\n",
    "        'classifier__n_estimators': [300, 500, 700],\n",
    "        'classifier__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'classifier__max_depth': [3, 4, 5, 6],\n",
    "        'classifier__subsample': [0.6, 0.8, 1.0],\n",
    "        'classifier__colsample_bytree': [0.6, 0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    rand_xgb = RandomizedSearchCV(xgb_pipeline, param_dist_xgb, n_iter=10, cv=3, scoring='f1', random_state=42, n_jobs=-1)\n",
    "    \n",
    "    rand_xgb.fit(X_train, y_train, classifier__sample_weight=w_train)\n",
    "\n",
    "    print('Best hyperparameters for XGBoost:', rand_xgb.best_params_)\n",
    "    \n",
    "    best_xgb = rand_xgb.best_estimator_\n",
    "    y_prob_xgb = best_xgb.predict_proba(X_test)[:,1]\n",
    "    y_pred_xgb = (y_prob_xgb >= 0.5).astype(int)\n",
    "    \n",
    "    acc_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "    prec_xgb = precision_score(y_test, y_pred_xgb)\n",
    "    recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "    f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "    roc_auc_xgb = roc_auc_score(y_test, y_prob_xgb)\n",
    "\n",
    "    print('Tuned XGBoost performance:')\n",
    "    print('  Accuracy:', acc_xgb)\n",
    "    print('  Precision:', prec_xgb)\n",
    "    print('  Recall:', recall_xgb)\n",
    "    print('  F1 score:', f1_xgb)\n",
    "    print('  ROC AUC:', roc_auc_xgb)\n",
    "else:\n",
    "    print('XGBoost library not available. Consider installing xgboost to run this section.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e309b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## 5. Exploring CatBoost\n",
    "\n",
    "# CatBoost is designed for categorical data and can handle categorical features natively without extensive preprocessing.\n",
    "# We attempt to import CatBoost; if unavailable, this section is skipped.\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    use_cat = True\n",
    "except ImportError:\n",
    "    use_cat = False\n",
    "\n",
    "if use_cat:\n",
    "    # For CatBoost we can keep categorical columns as integer codes (CatBoost handles them internally)\n",
    "    # We will build a CatBoost classifier with simple hyperparameter tuning via cross‑validation.\n",
    "    cat_features_indices = [df.columns.get_loc(col) for col in categorical_cols]  # indices of categorical features\n",
    "\n",
    "    cat_model = CatBoostClassifier(\n",
    "        iterations=500,\n",
    "        learning_rate=0.05,\n",
    "        depth=6,\n",
    "        loss_function='Logloss',\n",
    "        eval_metric='AUC',\n",
    "        random_seed=42,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Fit the model with sample weights\n",
    "    cat_model.fit(X_train, y_train, cat_features=cat_features_indices, sample_weight=w_train)\n",
    "\n",
    "    y_prob_cat = cat_model.predict_proba(X_test)[:,1]\n",
    "    y_pred_cat = (y_prob_cat >= 0.5).astype(int)\n",
    "\n",
    "    acc_cat = accuracy_score(y_test, y_pred_cat)\n",
    "    prec_cat = precision_score(y_test, y_pred_cat)\n",
    "    recall_cat = recall_score(y_test, y_pred_cat)\n",
    "    f1_cat = f1_score(y_test, y_pred_cat)\n",
    "    roc_auc_cat = roc_auc_score(y_test, y_prob_cat)\n",
    "\n",
    "    print('CatBoost performance:')\n",
    "    print('  Accuracy:', acc_cat)\n",
    "    print('  Precision:', prec_cat)\n",
    "    print('  Recall:', recall_cat)\n",
    "    print('  F1 score:', f1_cat)\n",
    "    print('  ROC AUC:', roc_auc_cat)\n",
    "else:\n",
    "    print('CatBoost library not available. Consider installing catboost to run this section.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756d552e",
   "metadata": {},
   "source": [
    "\n",
    "# ## 6. Discussion: Data aggregation, fairness and interpretability\n",
    "\n",
    "### Aggregated data\n",
    "\n",
    "The dataset used here is aggregated: each row represents multiple women with identical risk profiles, and the `count` column indicates the number of individuals in that group.  While weighting rows by `count` helps approximate the distribution of the original population, aggregation can mask within‑group variability and potentially distort estimates.  For instance, two women in the same row may still differ in unobserved factors that influence risk.  Future work should explore modelling the full individual‑level dataset or simulate synthetic individuals to better capture heterogeneity.\n",
    "\n",
    "### Fairness considerations\n",
    "\n",
    "Predictive models deployed in healthcare must be scrutinised for fairness across demographic groups.  For example, if a model under‑predicts risk for a particular race or age group, it could exacerbate disparities in screening and outcomes.  Here, we used class weighting and sample weights to mitigate overall imbalance, but further analyses—such as calculating group‑specific sensitivity/specificity or applying fairness metrics (e.g. equal opportunity)—would be necessary.  Additional variables like socioeconomic status and access to healthcare, which are not available in this dataset, could also influence fairness.\n",
    "\n",
    "### Interpretability\n",
    "\n",
    "Understanding how each feature influences predictions is critical for trust and adoption in clinical settings.  The feature importance plots from the ensemble models highlight which factors contribute most to predictions.  For more nuanced interpretation, one might use methods such as SHAP (SHapley Additive exPlanations) to quantify the contribution of each feature for individual predictions.  Moreover, simple logistic regression models, despite their lower predictive performance, provide coefficients that are easier to interpret and can be reported alongside more complex models.\n",
    "\n",
    "### External validation\n",
    "\n",
    "Validating the models on external datasets or prospective cohorts is essential to assess generalisability.  Since we do not have access to external data here, we relied on cross‑validation for hyperparameter tuning.  Future work should test the trained models on independent cohorts from different geographic or clinical settings.  This will help determine whether the models retain their predictive performance and fairness properties beyond the current dataset.\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
