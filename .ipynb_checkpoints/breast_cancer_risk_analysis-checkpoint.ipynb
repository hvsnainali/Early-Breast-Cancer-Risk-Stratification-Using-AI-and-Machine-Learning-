{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f83db624",
   "metadata": {},
   "source": [
    "\n",
    "# Breast Cancer Risk Analysis using Machine Learning\n",
    "\n",
    "This notebook demonstrates how to load and preprocess breast‑cancer risk data, train machine‑learning models to predict five‑year breast‑cancer risk using non‑invasive health variables, evaluate performance, assess fairness across subgroups, and interpret model predictions using SHAP.\n",
    "\n",
    "Adjust the `data_path` variable in the first code cell to point to your dataset (CSV file). If no path is provided, a synthetic dataset will be generated for demonstration purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f860541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, brier_score_loss, confusion_matrix, roc_curve, precision_recall_curve\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set path to CSV file; leave as None to use synthetic data\n",
    "data_path = None  # e.g., 'breast_cancer_data.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd604f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Synthetic data generation (same function as in the python script)\n",
    "\n",
    "def generate_synthetic_data(n_samples=100000, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    age_group = rng.integers(1, 14, size=n_samples)\n",
    "    age_midpoints = {1:23.5,2:32,3:37,4:42,5:47,6:52,7:57,8:62,9:67,10:72,11:77,12:82,13:87}\n",
    "    age = np.array([age_midpoints[i] for i in age_group])\n",
    "    bmi_group = rng.choice([1,2,3,4], size=n_samples, p=[0.35,0.35,0.2,0.1])\n",
    "    bmi_values = {1: rng.normal(21,2,n_samples),2:rng.normal(27,1.5,n_samples),3:rng.normal(32,1.5,n_samples),4:rng.normal(37,1.5,n_samples)}\n",
    "    bmi = np.array([bmi_values[i][j] for j,i in enumerate(bmi_group)])\n",
    "    race_eth = rng.choice([1,2,3,4,5,6], size=n_samples, p=[0.65,0.15,0.05,0.01,0.1,0.04])\n",
    "    first_degree_hx = rng.choice([0,1], size=n_samples, p=[0.85,0.15])\n",
    "    age_menarche = rng.choice([0,1,2], size=n_samples, p=[0.1,0.6,0.3])\n",
    "    age_first_birth = rng.choice([0,1,2,3,4], size=n_samples, p=[0.2,0.25,0.3,0.15,0.1])\n",
    "    BIRADS_breast_density = rng.choice([1,2,3,4], size=n_samples, p=[0.2,0.4,0.25,0.15])\n",
    "    current_hrt = rng.choice([0,1], size=n_samples, p=[0.7,0.3])\n",
    "    menopaus = rng.choice([1,2,3], size=n_samples, p=[0.5,0.4,0.1])\n",
    "    biophx = rng.choice([0,1], size=n_samples, p=[0.9,0.1])\n",
    "    breast_cancer_history = rng.choice([0,1], size=n_samples, p=[0.95,0.05])\n",
    "    year = rng.integers(2005, 2018, size=n_samples)\n",
    "    log_odds = (\n",
    "        (age - 50) * 0.05 + bmi * 0.08 + first_degree_hx*1.2 +\n",
    "        (age_menarche == 2) * 0.3 +\n",
    "        (age_first_birth == 3) * 0.5 +\n",
    "        (age_first_birth == 4) * 0.6 +\n",
    "        (BIRADS_breast_density == 4) * 0.7 +\n",
    "        (BIRADS_breast_density == 3) * 0.4 +\n",
    "        current_hrt * 0.5 +\n",
    "        biophx * 0.4 +\n",
    "        breast_cancer_history * 2.0\n",
    "    )\n",
    "    probs = 1/(1+np.exp(-log_odds))\n",
    "    cancer_5yr = rng.binomial(1, probs)\n",
    "    df = pd.DataFrame({\n",
    "        'year': year,\n",
    "        'age_group_5_years': age_group,\n",
    "        'race_eth': race_eth,\n",
    "        'first_degree_hx': first_degree_hx,\n",
    "        'age_menarche': age_menarche,\n",
    "        'age_first_birth': age_first_birth,\n",
    "        'BIRADS_breast_density': BIRADS_breast_density,\n",
    "        'current_hrt': current_hrt,\n",
    "        'menopaus': menopaus,\n",
    "        'bmi_group': bmi_group,\n",
    "        'biophx': biophx,\n",
    "        'breast_cancer_history': breast_cancer_history,\n",
    "        'age': age,\n",
    "        'BMI': bmi,\n",
    "        'cancer_5yr': cancer_5yr\n",
    "    })\n",
    "    return df\n",
    "\n",
    "# Load or generate data\n",
    "if data_path:\n",
    "    data = pd.read_csv(data_path)\n",
    "else:\n",
    "    data = generate_synthetic_data()\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a62645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate features and target\n",
    "X = data.copy()\n",
    "y = X.pop('cancer_5yr')\n",
    "\n",
    "# Identify numerical and categorical features\n",
    "numeric_features = ['year', 'age', 'BMI']\n",
    "categorical_features = [\n",
    "    'age_group_5_years', 'race_eth', 'first_degree_hx', 'age_menarche',\n",
    "    'age_first_birth', 'BIRADS_breast_density', 'current_hrt', 'menopaus',\n",
    "    'bmi_group', 'biophx', 'breast_cancer_history'\n",
    "]\n",
    "\n",
    "# Preprocessor: one-hot encode categorical variables\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "        ('num', 'passthrough', numeric_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Split into train and test sets (stratified by target)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6999beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to train models\n",
    "lr_clf = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('clf', LogisticRegression(max_iter=1000, solver='lbfgs', class_weight='balanced', n_jobs=-1))\n",
    "])\n",
    "rf_clf = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('clf', RandomForestClassifier(n_estimators=500, class_weight='balanced', n_jobs=-1, random_state=42))\n",
    "])\n",
    "xgb_clf = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('clf', xgb.XGBClassifier(\n",
    "        n_estimators=300, max_depth=4, learning_rate=0.05, subsample=0.8, colsample_bytree=0.8,\n",
    "        eval_metric='logloss', use_label_encoder=False, scale_pos_weight=(1/(y_train.mean())), n_jobs=-1, random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Fit models\n",
    "lr_clf.fit(X_train, y_train)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': lr_clf,\n",
    "    'Random Forest': rf_clf,\n",
    "    'Gradient Boosting': xgb_clf\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83ebee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate models\n",
    "performance_records = []\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:,1]\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    brier = brier_score_loss(y_test, y_proba)\n",
    "    performance_records.append({\n",
    "        'Model': name, 'Accuracy': accuracy, 'Precision': precision,\n",
    "        'Recall': recall, 'F1': f1, 'AUC': auc, 'Brier': brier\n",
    "    })\n",
    "\n",
    "perf_df = pd.DataFrame(performance_records)\n",
    "perf_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f715215",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8,6))\n",
    "for name, model in models.items():\n",
    "    y_proba = model.predict_proba(X_test)[:,1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc_score(y_test, y_proba):.3f})')\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196fe1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute fairness metrics: false positive and false negative rates by group\n",
    "\n",
    "def compute_group_rates(model, X_test, y_test, group_col):\n",
    "    X_tmp = X_test.copy()\n",
    "    y_pred = model.predict(X_test)\n",
    "    df_res = pd.DataFrame({group_col: X_tmp[group_col], 'y_true': y_test, 'y_pred': y_pred})\n",
    "    results = []\n",
    "    for group, subset in df_res.groupby(group_col):\n",
    "        tn, fp, fn, tp = confusion_matrix(subset['y_true'], subset['y_pred']).ravel()\n",
    "        fpr = fp/(fp+tn) if (fp+tn)>0 else 0\n",
    "        fnr = fn/(fn+tp) if (fn+tp)>0 else 0\n",
    "        results.append({group_col: group, 'FPR': fpr, 'FNR': fnr, 'Count': len(subset)})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "fairness_age = compute_group_rates(models['Gradient Boosting'], X_test, y_test, 'age_group_5_years')\n",
    "fairness_race = compute_group_rates(models['Gradient Boosting'], X_test, y_test, 'race_eth')\n",
    "\n",
    "fairness_age, fairness_race\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce5b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Explain gradient boosting model using SHAP (sample 200 instances)\n",
    "explainer = shap.Explainer(models['Gradient Boosting'].named_steps['clf'])\n",
    "# Transform data to model input\n",
    "X_transformed = models['Gradient Boosting'].named_steps['preprocess'].transform(X_test)\n",
    "# Choose a sample for explanation\n",
    "sample_indices = np.random.choice(len(X_test), size=min(200, len(X_test)), replace=False)\n",
    "X_sample = X_transformed[sample_indices]\n",
    "shap_values = explainer(X_sample)\n",
    "\n",
    "# Summary plot\n",
    "shap.summary_plot(shap_values, features=X_sample, feature_names=explainer.feature_names)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
